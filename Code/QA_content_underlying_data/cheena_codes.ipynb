{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c08669-95d0-4b82-bd9e-db5cd4181aae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai pandas openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a339fa74-545a-41a9-9160-2f9248fcd283",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load libraries"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import openpyxl\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf7edc2-1692-4b8c-948b-d8dfc4747186",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "LLM API "
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2220072380334347.7.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are a helpful assistant whose role is to quality assure the content in the input data. Your tasks inclValidating accuracy of the provided information.Cross-checking consistency of the content with any tables, plots, or visual data representations given.Highlighting discrepancies or errors between the written content and the numerical/graphical data.\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=5000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e788ef63-09ac-41bb-ba56-a641fb0d3143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2220072380334347.7.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-claude-3-7-sonnet\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are a helpful assistant whose role is to quality assure the content in the input data. Your tasks inclValidating accuracy of the provided information.Cross-checking consistency of the content with any tables, plots, or visual data representations given.Highlighting discrepancies or errors between the written content and the numerical/graphical data.\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=5000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d277043-097a-4ad4-bf83-e458bb4cf79b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-docx\n",
    "import pandas as pd\n",
    "import docx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78bda179-7808-4cb3-bb4f-42a587e6a48c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d99f847-3b3e-4212-ac38-97c617bebe2c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load the data"
    }
   },
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "# Load the Word file which is in the same folder\n",
    "doc = docx.Document(\"KS4_Commentary_202324_revised.docx\")\n",
    "\n",
    "# Display the content of the Word file\n",
    "for para in doc.paragraphs:\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f0983fc-a66c-403b-bb50-b41111be554c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load ECF data"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Word file which is in the same folder\n",
    "import docx\n",
    "# Load the Word file which is in the same folder\n",
    "doc = docx.Document(\"ecf_text.docx\")\n",
    "\n",
    "\n",
    "# Display the content of the Word file\n",
    "for para in doc.paragraphs:\n",
    "    print(para.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77f5a24e-16ff-4794-a3cf-784f74c0953b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "csv_df = pd.read_csv(\"teacher_leader_development_ecf_2024_25.csv\")\n",
    "meta_df =pd.read_csv(\"teacher_leader_development_ecf_2024_25.meta.csv\")\n",
    "mentors =pd.read_csv(\"teacher_leader_development_ecf_mentor_2024_25.csv\")\n",
    "mentors_meta = pd.read_csv(\"teacher_leader_development_ecf_mentor_2024_25.meta.csv\")\n",
    "retention = pd.read_csv(\"teacher_leader_development_ecf_retention_2024_25.csv\")\n",
    "retention_meta = pd.read_csv(\"teacher_leader_development_ecf_retention_2024_25.meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed81668a-c41e-481f-bc78-f93b857bd46a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##checking for headlines: \n",
    "text = \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip()])\n",
    "\n",
    "# Initialize Databricks LLM client\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2220072380334347.7.azuredatabricks.net/serving-endpoints\"   # replace with your Databricks endpoint\n",
    ")\n",
    "\n",
    "# Simple query to check if the LLM understands\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-claude-3-7-sonnet\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Here is my document text:\\n\\n{text}\\n\\nCan you list any headlines you detect?\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "doc_headlines = response.choices[0].message.content.split(\"\\n\")\n",
    "doc_headlines = [h.strip() for h in doc_headlines if h.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b9038bf-f2b7-467d-a53d-6db3042adff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(doc_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f0f606e-d442-45e1-b558-f99d50753a0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##### now onto the csv files: only keeping the values which are relavnt for healdines:  \n",
    "# #Function to filter a dataframe: keep 'time_period' plus columns from 'breakdown' to 'group_name'\n",
    "def filter_df(df):\n",
    "    if \"breakdown\" in df.columns and \"time_period\" in df.columns:\n",
    "        start_idx = df.columns.get_loc(\"breakdown\")\n",
    "        # Keep all columns from \"breakdown\" to the end\n",
    "        cols_to_keep = [\"time_period\"] + list(df.columns[start_idx:])\n",
    "        return df[cols_to_keep]\n",
    "    else:\n",
    "        print(\"One or more required columns are missing.\")\n",
    "        return df\n",
    "\n",
    "\n",
    "# Apply filtering\n",
    "filtered_csv_df = filter_df(csv_df)\n",
    "filtered_mentors = filter_df(mentors)\n",
    "filtered_retention = filter_df(retention)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e47c96bd-a051-4ada-acc3-aa0cddd4be5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview\n",
    "print(filtered_csv_df.head())\n",
    "print(filtered_mentors.head())\n",
    "print(filtered_retention.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1707c766-0fd4-4e0b-acec-a9f7fe1d1137",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers_from_df(df):\n",
    "    \"\"\"Extract all integers from all columns in a DataFrame.\"\"\"\n",
    "    numbers = set()\n",
    "    for col in df.columns:\n",
    "        # Convert everything to string to make regex work\n",
    "        for val in df[col].astype(str):\n",
    "            found = re.findall(r'\\d+', val)\n",
    "            numbers.update(map(int, found))\n",
    "    return numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f774ee7b-4002-4b05-87ac-9800e9cd803d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extract numbers from each filtered DataFrame\n",
    "csv_numbers = extract_numbers_from_df(filtered_csv_df)\n",
    "mentor_numbers = extract_numbers_from_df(filtered_mentors)\n",
    "retention_numbers = extract_numbers_from_df(filtered_retention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb0a216c-2451-4a47-bc93-f149a9dbc457",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine all numbers\n",
    "all_csv_numbers = csv_numbers | mentor_numbers | retention_numbers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2786c35-3b02-4c05-bfb8-9d3c9dc99f80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(doc_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5b303cc-f2dd-4fd9-8b7a-147d02722303",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#### extract numbers from text data\n",
    "import re\n",
    "\n",
    "# Join all lines into one string\n",
    "text = \" \".join(doc_headlines)\n",
    "\n",
    "# Regex to find numbers (integers, decimals, and numbers with commas)\n",
    "all_numbers = re.findall(r'\\d[\\d,]*\\.?\\d*', text)\n",
    "\n",
    "# Convert numbers to int or float\n",
    "numbers = []\n",
    "for num in all_numbers:\n",
    "    # Ignore years like 2021-2024\n",
    "    if re.match(r'^(20\\d{2})$', num):\n",
    "        continue\n",
    "    # Ignore fiscal-year style numbers like 2023/24\n",
    "    if re.match(r'^20\\d{2}/\\d{2}$', num):\n",
    "        continue\n",
    "    # Convert to int or float\n",
    "    numbers.append(float(num.replace(',', '')) if '.' in num else int(num.replace(',', '')))\n",
    "\n",
    "print(numbers)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a84ea22-127a-461c-a25c-f0003628fd06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combine all CSV numbers into one list\n",
    "all_csv_numbers = csv_numbers | mentor_numbers | retention_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35d2f230-ba87-4598-9629-d539c8c274a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Option 2: Check if all numbers from text exist in CSVs\n",
    "all_in_csv = all(num in all_csv_numbers for num in numbers)\n",
    "print(\"All numbers from text exist in CSVs?\", all_in_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4faf0f31-7fee-45d4-9474-5f240bd42ec5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "diff_text_not_in_csv = [num for num in numbers if num not in all_csv_numbers]\n",
    "diff_csv_not_in_text = [num for num in all_csv_numbers if num not in numbers]\n",
    "\n",
    "print(\"Numbers in text but not in CSVs:\", diff_text_not_in_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca83115d-4a3d-48ca-a06a-8cc3bf4abb82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(doc_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2bb8b6-741f-44c9-ab8d-2af16d0593e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sections = {}\n",
    "current_heading = None\n",
    "current_content = []\n",
    "\n",
    "def is_bold_heading(paragraph):\n",
    "    \"\"\"Check if the paragraph contains bold text (used as heading).\"\"\"\n",
    "    return any(run.bold for run in paragraph.runs) and paragraph.text.strip()\n",
    "\n",
    "for para in doc.paragraphs:\n",
    "    text = para.text.strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    if is_bold_heading(para):\n",
    "        if current_heading and current_content:\n",
    "            sections[current_heading] = \"\\n\".join(current_content)\n",
    "            current_content = []\n",
    "        current_heading = text\n",
    "    else:\n",
    "        current_content.append(text)\n",
    "\n",
    "if current_heading and current_content:\n",
    "    sections[current_heading] = \"\\n\".join(current_content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a7ffe55-4745-4bed-bddb-1468f9132ea0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert into DataFrames\n",
    "dfs = {heading: pd.DataFrame({\"Content\": content.split(\"\\n\")}) \n",
    "       for heading, content in sections.items()}\n",
    "\n",
    "# Initialize Databricks LLM client\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2220072380334347.7.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "def extract_headlines_from_section(df, section_name):\n",
    "    \"\"\"Send one section to the LLM and return detected headlines.\"\"\"\n",
    "    section_text = \"\\n\".join(df[\"Content\"].tolist())\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-claude-3-7-sonnet\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Here is my document section: {section_name}\\n\\n{section_text}\\n\\nCan you list any headlines you detect?\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    raw_output = response.choices[0].message.content\n",
    "    doc_headlines = [h.strip() for h in raw_output.split(\"\\n\") if h.strip()]\n",
    "    return doc_headlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74a9a7d4-800b-4375-ad5f-4bb58679dce7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(doc_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e800403c-29f3-4382-82ba-975e032e0045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each section and extract headlines\n",
    "all_headlines = {}\n",
    "for heading, df in dfs.items():\n",
    "    print(f\"\\n### DataFrame for: {heading} ###\")\n",
    "    print(df)\n",
    "\n",
    "    section_headlines = extract_headlines_from_section(df, heading)\n",
    "    all_headlines[heading] = section_headlines\n",
    "\n",
    "    print(\"\\nDetected headlines:\", section_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0ac26f8-ba91-488a-9137-bd13ec4137b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "try to scale it"
    }
   },
   "outputs": [],
   "source": [
    "############# try ######\n",
    "import docx\n",
    "\n",
    "doc = docx.Document(\"ecf_text.docx\")\n",
    "\n",
    "sections = {}\n",
    "current_heading = None\n",
    "current_content = []\n",
    "\n",
    "def is_bold_heading(paragraph):\n",
    "    \"\"\"Check if the entire paragraph is bold (heading).\"\"\"\n",
    "    return any(run.bold for run in paragraph.runs) and paragraph.text.strip()\n",
    "\n",
    "for para in doc.paragraphs:\n",
    "    text = para.text.strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    if is_bold_heading(para):\n",
    "        # Save previous section if it exists\n",
    "        if current_heading and current_content:\n",
    "            sections[current_heading] = \"\\n\".join(current_content)\n",
    "            current_content = []\n",
    "        current_heading = text  # new heading\n",
    "    else:\n",
    "        current_content.append(text)\n",
    "\n",
    "# Save last section\n",
    "if current_heading and current_content:\n",
    "    sections[current_heading] = \"\\n\".join(current_content)\n",
    "\n",
    "# Display results\n",
    "for heading, content in sections.items():\n",
    "    print(f\"=== {heading} ===\")\n",
    "    print(content)\n",
    "    print()\n",
    "\n",
    "\n",
    "    sections = {}\n",
    "current_heading = None\n",
    "current_content = []\n",
    "\n",
    "def is_bold_heading(paragraph):\n",
    "    \"\"\"Check if the paragraph contains bold text (used as heading).\"\"\"\n",
    "    return any(run.bold for run in paragraph.runs) and paragraph.text.strip()\n",
    "\n",
    "for para in doc.paragraphs:\n",
    "    text = para.text.strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    if is_bold_heading(para):\n",
    "        # Save previous section if it exists\n",
    "        if current_heading and current_content:\n",
    "            sections[current_heading] = \"\\n\".join(current_content)\n",
    "            current_content = []\n",
    "        current_heading = text\n",
    "    else:\n",
    "        current_content.append(text)\n",
    "\n",
    "# Save last section\n",
    "if current_heading and current_content:\n",
    "    sections[current_heading] = \"\\n\".join(current_content)\n",
    "\n",
    "# Convert each section into its own DataFrame\n",
    "dfs = {}\n",
    "for heading, content in sections.items():\n",
    "    dfs[heading] = pd.DataFrame({\"Content\": content.split(\"\\n\")})\n",
    "\n",
    "# Example: access a specific DataFrame by heading\n",
    "for heading, df in dfs.items():\n",
    "    print(f\"\\n### DataFrame for: {heading} ###\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f46c9b3-83f1-48ad-b2a6-77122621a89a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "checking consistency of summary with the data"
    }
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-claude-3-7-sonnet\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that checks summaries for accuracy against provided data.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "Here is the source text:\n",
    "{full_text}\n",
    "\n",
    "Here is the table data:\n",
    "{table_data}\n",
    "\n",
    "Here is a summary I wrote:\n",
    "{user_summary}\n",
    "\n",
    "Check if the summary accurately reflects the text AND the table. \n",
    "- Highlight any inconsistencies. \n",
    "- Suggest corrections if needed. \n",
    "- If everything is correct, just say 'Summary is consistent with data'.\n",
    "\"\"\"\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=5000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ce91aec-2958-43b1-93ca-95bc8b897024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: doc_headlines is a list of summaries/headlines\n",
    "# csv_numbers is a dict or list of numbers extracted from your CSV\n",
    "\n",
    "for headline in doc_headlines:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-claude-3-7-sonnet\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an AI assistant that checks summaries for factual accuracy against numeric data and corrects any mistakes.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"\n",
    "Check the following summary for accuracy:\n",
    "\n",
    "Summary:\n",
    "{headline}\n",
    "\n",
    "Reference numbers from the table:\n",
    "{csv_numbers}\n",
    "\n",
    "- Identify any factual inaccuracies in the summary compared to the table numbers.\n",
    "- Suggest a corrected version if needed.\n",
    "- If the summary is correct, just confirm it.\n",
    "\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    print(\"Original headline:\", headline)\n",
    "    print(\"LLM feedback:\", response.choices[0].message.content)\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cheena_codes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
