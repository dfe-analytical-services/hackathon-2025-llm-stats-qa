{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cca30052-451c-4c70-b752-0c6f5994130c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Create policy focused narrative sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "667c9ef2-3ebc-4248-a6a4-d329686e94ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install openai\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27ec5e32-99ce-4880-98ed-937193e8a1ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import libraries"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f88cbf7f-0f33-4eb9-afc0-80f2b08cc7f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read and filter the underlying data"
    }
   },
   "outputs": [],
   "source": [
    "national_char_data = pd.read_csv(\"/Workspace/Users/daniel.dodgson@education.gov.uk/hackathon-2025-llm-stats-qa/data/202324_national_char_data_revised.csv\")\n",
    "national_char_metadata = pd.read_csv(\"/Workspace/Users/daniel.dodgson@education.gov.uk/hackathon-2025-llm-stats-qa/data/202324_national_char_data_revised.meta.csv\")\n",
    "\n",
    "# Filter for only All state-funded school type\n",
    "national_char_filtered_data = national_char_data[national_char_data['establishment_type_group'] == 'All state-funded']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['religious_denomination'] == 'Total']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['admission_type'] == 'Total']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['sen_primary_need'] == 'Total']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['sen_status'] == 'Total']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['free_school_meals'] == 'Total']\n",
    "national_char_filtered_data = national_char_filtered_data[national_char_filtered_data['ethnicity_minor'] == 'Total']\n",
    "\n",
    "\n",
    "national_char_filtered_data = national_char_filtered_data[['time_period', 'sex', 'ethnicity_major', 'sen_provision', 'disadvantage', 'first_language', 't_pupils', 'avg_att8', 'pt_l2basics_95', 'avg_p8score', 'pt_ebacc_e_ptq_ee', 'avg_ebaccaps']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5d44746-532b-4ee5-89bd-53cfa26923b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Convert data to JSON format"
    }
   },
   "outputs": [],
   "source": [
    "json_data_for_prompt = national_char_filtered_data.to_json(orient=\"records\")\n",
    "json_metadata_for_prompt = national_char_metadata.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2743c304-d3d1-4b1b-8438-03515344d610",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a simple query"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the API key from Databricks secrets\n",
    "DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=DATABRICKS_TOKEN,\n",
    "    base_url=\"https://adb-2220072380334347.7.azuredatabricks.net/serving-endpoints\"\n",
    ")\n",
    "\n",
    "#What is the accordion name?\n",
    "accordion_title = \"EBacc entry and achievement\"\n",
    "\n",
    "# What indicators are the focus?\n",
    "performance_measures = [\n",
    "    \"pt_ebacc_e_ptq_ee\",\n",
    "    \"pt_ebacc_94\",\n",
    "    \"pt_ebacc_95\",\n",
    "    \"avg_ebaccaps\"\n",
    "]\n",
    "\n",
    "# Define the prompt with the data and metadata\n",
    "prompt = f\"\"\"\n",
    "Here is the data:\n",
    "{json_data_for_prompt}\n",
    "Here is the metadata: \n",
    "{json_metadata_for_prompt}\n",
    "Please summarize the data within the data file with a focus on the following indicators: {performance_measures}. Use the metadata to understand what those indicators are; don't guess what the indicators are the metadata will tell you. The summary needs to fit under the heading {accordion_title}. Focus on the overall trends over time (the time_period column specifies the academic year in the format 202324 is 2023/24). but do pick out any very (emphasis on very!) interesting characteristic effects. Please also provide a table summarising the most interesting story. Please note the structure of the data, there are characteristic columns, i.e., denoted as filter columns in the metadata. When all these filter columns equal Total then you are looking at the overall data.\n",
    "\"\"\"\n",
    "# print(prompt)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are creating narrative sections around specific policy areas based on the data provided. The narrative is a national statistics, statistical release so it has to be very matter-of-fact. \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.01,\n",
    "    max_tokens=5000\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "create_narrative_sections",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
